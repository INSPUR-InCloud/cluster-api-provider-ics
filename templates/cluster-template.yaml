---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: Cluster
metadata:
  name: '${ CLUSTER_NAME }'
  namespace: '${ NAMESPACE }'
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 192.168.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1alpha3
    kind: KubeadmControlPlane
    name: '${ CLUSTER_NAME }'
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
    kind: ICSCluster
    name: '${ CLUSTER_NAME }'
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: HAProxyLoadBalancer
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: '${ CLUSTER_NAME }'
  name: '${ CLUSTER_NAME }'
  namespace: '${ NAMESPACE }'
spec:
  user:
    authorizedKeys:
    - '${ ICS_SSH_AUTHORIZED_KEY }'
    name: capics
  virtualMachineConfiguration:
    cloneMode: linkedClone
    cluster: '${ ICS_CLUSTER }'
    datacenter: '${ ICS_DATACENTER }'
    datastore: '${ ICS_DATASTORE }'
    diskGiB: 25
    memoryMiB: 8192
    network:
      devices:
      - dhcp4: true
        networkName: '${ ICS_NETWORK }'
    numCPUs: 2
    resourcePool: '${ ICS_RESOURCE_POOL }'
    server: '${ ICS_SERVER }'
    template: '${ ICS_HAPROXY_TEMPLATE }'
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: ICSCluster
metadata:
  name: '${ CLUSTER_NAME }'
  namespace: '${ NAMESPACE }'
spec:
  cloudProviderConfiguration:
    global:
      insecure: true
      secretName: cloud-provider-ics-credentials
      secretNamespace: kube-system
    iCenter:
      ${ ICS_SERVER }:
        datacenters: '${ ICS_DATACENTER }'
    network:
      name: '${ ICS_NETWORK }'
    providerConfig:
      cloud:
        controllerImage: icsccm:v1.5
      storage:
        attacherImage: quay.io/k8scsi/csi-attacher:v1.1.1
        controllerImage: ics-csi-driver:latest
        livenessProbeImage: quay.io/k8scsi/livenessprobe:v1.1.0
        metadataSyncerImage: ics-csi-syncer:latest
        nodeDriverImage: ics-csi-driver:latest
        provisionerImage: quay.io/k8scsi/csi-provisioner:v1.2.2
        registrarImage: quay.io/k8scsi/csi-node-driver-registrar:v1.1.0
    workspace:
      cluster: '${ ICS_CLUSTER }'
      datacenter: '${ ICS_DATACENTER }'
      datastore: '${ ICS_DATASTORE }'
      resourcePool: '${ ICS_RESOURCE_POOL }'
      server: '${ ICS_SERVER }'
  loadBalancerRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
    kind: HAProxyLoadBalancer
    name: '${ CLUSTER_NAME }'
  server: '${ ICS_SERVER }'
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: ICSMachineTemplate
metadata:
  name: '${ CLUSTER_NAME }'
  namespace: '${ NAMESPACE }'
spec:
  template:
    spec:
      cloneMode: linkedClone
      cluster: '${ ICS_CLUSTER }'
      datacenter: '${ ICS_DATACENTER }'
      datastore: '${ ICS_DATASTORE }'
      diskGiB: 25
      memoryMiB: 8192
      network:
        devices:
        - dhcp4: true
          networkName: '${ ICS_NETWORK }'
      numCPUs: 2
      resourcePool: '${ ICS_RESOURCE_POOL }'
      server: '${ ICS_SERVER }'
      template: '${ ICS_TEMPLATE }'
---
apiVersion: controlplane.cluster.x-k8s.io/v1alpha3
kind: KubeadmControlPlane
metadata:
  name: '${ CLUSTER_NAME }'
  namespace: '${ NAMESPACE }'
spec:
  infrastructureTemplate:
    apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
    kind: ICSMachineTemplate
    name: '${ CLUSTER_NAME }'
  kubeadmConfigSpec:
    clusterConfiguration:
      apiServer:
        extraArgs:
          cloud-provider: external
      controllerManager:
        extraArgs:
          cloud-provider: external
    initConfiguration:
      nodeRegistration:
        criSocket: /var/run/containerd/containerd.sock
        kubeletExtraArgs:
          cloud-provider: external
        name: '{{ ds.meta_data.hostname }}'
    joinConfiguration:
      nodeRegistration:
        criSocket: /var/run/containerd/containerd.sock
        kubeletExtraArgs:
          cloud-provider: external
        name: '{{ ds.meta_data.hostname }}'
    preKubeadmCommands:
    - hostname "{{ ds.meta_data.hostname }}"
    - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
    - echo "127.0.0.1   localhost" >>/etc/hosts
    - echo "127.0.0.1   {{ ds.meta_data.hostname }}" >>/etc/hosts
    - echo "{{ ds.meta_data.hostname }}" >/etc/hostname
    useExperimentalRetryJoin: true
    users:
    - name: capics
      sshAuthorizedKeys:
      - '${ ICS_SSH_AUTHORIZED_KEY }'
      sudo: ALL=(ALL) NOPASSWD:ALL
  replicas: ${ CONTROL_PLANE_MACHINE_COUNT }
  version: '${ KUBERNETES_VERSION }'
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: KubeadmConfigTemplate
metadata:
  name: '${ CLUSTER_NAME }-md-0'
  namespace: '${ NAMESPACE }'
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          criSocket: /var/run/containerd/containerd.sock
          kubeletExtraArgs:
            cloud-provider: external
          name: '{{ ds.meta_data.hostname }}'
      preKubeadmCommands:
      - hostname "{{ ds.meta_data.hostname }}"
      - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
      - echo "127.0.0.1   localhost" >>/etc/hosts
      - echo "127.0.0.1   {{ ds.meta_data.hostname }}" >>/etc/hosts
      - echo "{{ ds.meta_data.hostname }}" >/etc/hostname
      users:
      - name: capics
        sshAuthorizedKeys:
        - '${ ICS_SSH_AUTHORIZED_KEY }'
        sudo: ALL=(ALL) NOPASSWD:ALL
---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: MachineDeployment
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: '${ CLUSTER_NAME }'
  name: '${ CLUSTER_NAME }-md-0'
  namespace: '${ NAMESPACE }'
spec:
  clusterName: '${ CLUSTER_NAME }'
  replicas: ${ WORKER_MACHINE_COUNT }
  selector:
    matchLabels: {}
  template:
    metadata:
      labels:
        cluster.x-k8s.io/cluster-name: '${ CLUSTER_NAME }'
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: KubeadmConfigTemplate
          name: '${ CLUSTER_NAME }-md-0'
      clusterName: '${ CLUSTER_NAME }'
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
        kind: ICSMachineTemplate
        name: '${ CLUSTER_NAME }'
      version: '${ KUBERNETES_VERSION }'
